In this thesis, we explored different properties of Blockchain-based Federated Learning systems, as well as how those properties impact the system in terms of execution time, accuracy and resource consumption. In addition, we also designed and implemented a modular framework for BFL such that we could perform our experiments, as well as empower future research. Specifically, we started this thesis by setting the main research question of \textit{"What is the impact of different Blockchain-based Federated Learning properties and techniques on execution time, convergence and accuracy, as well as communication and computation costs?"}. The answer to this question will be discussed further ahead.

\section{General Conclusions}\label{conclusions:general}

% Blockchain properties: traceability, auditability / immutability, persistency / decentralization / authentication

% Latency: there is always a ~1.5 second latency when waiting for transactions. Considering that each training round has at least $C+S+2$ transactions, that is quite a lot of time. Trade-off between what blockchain offers (traceability, auditability, decentralization, persistency and authentication) vs. time.

% Consensus Algorithms
%     Computation Costs: PoW >> QBFT = PoA
%     Communication Costs: QBFT >> PoW = PoA
%     PoA can be considered less decentralized, which can be an issue in public networks. Trade-off with degree of decentralization.
    
% Participant Selection Methods
%     Computation and Communication Costs: PoW = QBFT = PoA
%     Fairness: Random > FCFS

% Scoring Technique
%     Computation and Communication Costs:
%         Server: Multi-KRUM > BlockFlow and Marginal Gain
%         Clients: BlockFlow and Marginal Gain > Multi-KRUM
%     Accuracy: Marginal Gain > Multi-KRUM > BlockFlow

% Decision Tree For Scoring Technique:
%     Low-Powered
%         Yes: 1. Multi-KRUM
%         No: 1. Marginal Gain, 2. BlockFlow

% + Clients + Low Powered = Multi-KRUM
% + Clients + High Powered = Marginal Gain
% - Clients + Low Powered = Multi- KRUM
% - Clients + High Powered = Marginal gain

% Privacy: Multi-KRUM and Marginal Gain

\section{Contributions}\label{conclusions:contributions}

The contributions of this work are as follows:

\begin{enumerate}
    \item Designed and implemented the first open-source modular framework for Blockchain-based Federated Learning that can be easily adapted to support new scoring, aggregation and privacy techniques. This framework can be used to empower future research.
    
    \item Provided the first comparative study of how different aspects of Blockchain-based Federated Learning, namely consensus algorithms, participant selection techniques and scoring techniques, impact the accuracy, execution time and communication and computation costs.
    
    \item Provided the first comparative study of how the number of training devices and different degrees of privacy impact the accuracy, execution time and communication and computation costs of different scoring techniques.
    
    \item Designed and implemented the first open-source proof-of-concept of a Blockchain-based Vertical Federated Learning.
\end{enumerate}

\section{Future Work}\label{conclusions:future_work}

% Build a tool that uses the smart contract to visualize the training process.

% Investigate how consensus algorithms tailored for FL could be applied to ethereum such that it is still possible to re-use some part of an already existing and testedblockchain platfor??