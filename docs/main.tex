\documentclass[a4paper]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage[top=50pt,bottom=60pt,left=1in,right=1in]{geometry}
\usepackage{natbib}
\usepackage{graphicx}


%% These few lines make a distinction between latex and pdflatex calls and they
%% bring in essential packages for graphics and font handling.
%% Note that due to the \DeclareGraphicsExtensions{} call it is no longer necessary
%% to provide the the path and extension of a graphics file:
%% \includegraphics{diamondrule} is completely sufficient.
%%
\ifpdf%                                % if we use pdflatex
  \pdfoutput=1\relax                   % create PDFs from pdfLaTeX
  \pdfcompresslevel=9                  % PDF Compression
  \pdfoptionpdfminorversion=7          % create PDF 1.7
  \ExecuteOptions{pdftex}
  \usepackage{graphicx}                % allow us to embed graphics files
  \DeclareGraphicsExtensions{.pdf,.png,.jpg,.jpeg} % for pdflatex we expect .pdf, .png, or .jpg files
\else%                                 % else we use pure latex
  \ExecuteOptions{dvips}
  \usepackage{graphicx}                % allow us to embed graphics files
  \DeclareGraphicsExtensions{.eps}     % for pure latex we expect eps files
\fi%

\graphicspath{{figures/}{pictures/}{images/}{./}} % where to search for the images

\usepackage{microtype}                 % use micro-typography (slightly more compact, better to read)
\PassOptionsToPackage{warn}{textcomp}  % to address font issues with \textrightarrow
\usepackage{textcomp}                  % use better special symbols
\usepackage{mathptmx}                  % use matching math font
\usepackage{times}                     % we use Times as the main font
\renewcommand*\ttdefault{txtt}         % a nicer typewriter font
\usepackage{hyperref}                  % to enable \autoref
\usepackage{subcaption}                % to support captions for subfigures
\usepackage{enumitem}
\usepackage{physics}

% Title
\title{Volume Rendering Assignment\\2IMV20\\Eindhoven University of Technology}

% Authors and group. Replace with your names and group number
\author{Nimo Beeren \quad Henrique Dias \quad Gabriela Slavova\\Group 13}
\date{December 2020}

% Begin document
\begin{document}

\maketitle

\section{Introduction}

In class, various rendering methods used to visualize 3D scalar data have been discussed \citep{2imv20_2}. In this report, we describe our implementation of some of these methods and compare them by applying them to various datasets.

Each section contains a reference to the method where the implementation can be found. Unless otherwise mentioned, these methods are members of the {\tt RaycastRenderer} class.

\section{Implementation}

\subsection{Raycasting}
\label{subsec:raycasting}

\paragraph{Trilinear interpolation}

In order to achieve a smooth transition of intensity between voxels, we apply some interpolation. Given a 3D pixel coordinate $X$, we find the voxels $X_0 \ldots X_7$ such that these voxels form the vertices of a cube that contains $X$. Using the known intensities $S_{X_0}\ldots S_{X_7}$, we apply trilinear interpolation to obtain an approximate intensity for the given pixel coordinate:
\begin{align*}
  S_X =\;&(1 - \alpha) (1 - \beta) (1 - \gamma) S_{X_0}
    + \alpha (1 - \beta) (1 - \gamma) S_{X_1}\\
    &+ (1 - \alpha) \beta (1 - \gamma) S_{X_2}
    + \alpha \beta (1 - \gamma) S_{X_3}\\
    &+ (1 - \alpha) (1 - \beta) \gamma S_{X_4}
    + \alpha (1 - \beta) \gamma S_{X_5}\\
    &+ (1 - \alpha) \beta \gamma S_{X_6}
    + \alpha \beta \gamma S_{X_7}
\end{align*}
We expect that the visualization of the data after trilinear interpolation is implemented will be smoother and this can be observed in \autoref{fig:trilinear}. The implementation can be found in the method {\tt getVoxelTrilinear}.

\paragraph{Compositing}
\label{ray_composite}

To implement the compositing ray function, we applied a front-to-back compositing strategy, similar to the back-to-front strategy studied in class \citep{2imv20_2}:
$$I(p)=\sum^{n-1}_{i=0}c_i\prod^{n-1}_{j=i+1}(1-\alpha_j)$$
where $\alpha_j$ is the voxel opacity and $c_i$ the color. Since this calculation is based on a sum, we calculate it iteratively. Using the given {\tt rayVector} and {\tt sampleStep} values, we can calculate the incremental step to go from {\tt entryPoint} to {\tt exitPoint}. For each voxel, we calculate the value using trilinear interpolation and the trilinear gradient and add it to the final voxel color. The implementation can be found in the method {\tt traceRayComposite}.

\subparagraph{MIP vs compositing}

When comparing MIP with the compositing rendering method, we observe that, when using MIP, some information can be lost as this method only accounts for the highest intensity voxel in the viewing ray. If there is information behind the highest intensity voxel, it is not visible. On the other hand, with composite, since it is actually the composition of all voxels in a certain ray, we can visualize the elements in many levels of depth. You can see some of those differences on \autoref{fig:mipscomp}.

\paragraph{Interactive mode}
\label{speed_up}

To make the application more responsive while manipulating the camera, we lower the resolution during rendering. We can do that by changing the values of the variables {\tt increment} and {\tt sampleStep} to bigger ones leading to lowering the number of steps along the view ray and the number of pixels sampled.  The new values for interactive mode were chosen using the trial-and-error method to find a workable trade-off between rendering quality and performance. In \autoref{fig:speedup} can be observed both the time of the rendering in interactive mode before and after the changes, and the the quality of the image. The implementation consists of a simple if-statement near the top of the {\tt raycast} method.

\paragraph{Gradients}
\label{subsec:gradients}

The work related to gradients consists of two main parts:

\begin{enumerate}[noitemsep]
  \item Computing the gradients, implemented in method {\tt compute} of class {\tt GradientVolume}.
  \item Trilinear interpolation of gradients, implemented in method {\tt getGradientTrilinear}.
\end{enumerate}

\noindent When the volume is first loaded, an approximate gradient is computed for all voxels, using the method described by Levoy \citep{levoy_1988}. The resulting vectors are stored in a lookup table (LUT).

To achieve a smooth transition of the gradient between voxels, we apply trilinear interpolation in similar fashion as done with the voxel intensities. To aid with scalar multiplication and vector addition, the utility methods {\tt scale} and {\tt add} respectively were implemented in the {\tt VoxelGradient} class.

\subsection{Isosurface raycasting and shading}
\label{subsec:isosurface}

\paragraph{Isosurface raycasting}

Isosurfaces are defined by
 $$f(x; y; z) = C$$ 
Where $C$ is a constant known as the isovalue. Similarly to the compositing method described in \autoref{subsec:raycasting}, we use the given {\tt rayVector} and {\tt sampleStep} values to calculate the incremental step to go from {\tt entryPoint} to {\tt exitPoint}. For each voxel, we use trilinear interpolation to calculate the value and then we compare it to the value of {\tt isoValueFront} which is the value specified in the GUI of the application. If the current value is greater we check if shading is enabled and apply it using {\tt computePhongShading} if needed, and return the {\tt isoColorFront} which is the chosen color in the GUI of the application or the newly computed color after the shading is applied to the  {\tt isoColorFront}. If no greater than {\tt isoValueFront} values are found, black is returned.

After implementation we should be able to clearly see parts with the same value. The result without shading enabled can be seen in \autoref{fig:isosurface}. Rendering using this method is fast and does not cause any delays in the interaction with the GUI. The implementation can be found in the method {\tt traceRayIso}.

\paragraph{Phong shading}

Phong's shading model was presented in class \citep{2imv20_2}:

$$ I = I_a k_a + I_lk_d(L \cdot N)+I_l k_s (V \cdot R)^\alpha$$

\noindent where

\begin{itemize}
  \item $I_a$ and $I_l$ refer to the ambient light and to the object light, respectively.
  \item $k_a$, $k_d$ and $k_s$ refer to the ambient, diffuse and specular parameters, respectively.
  \item $L$ is the light vector.
  \item $N$ is the normal which can be calculated with the given gradient $G$ by applying $N = {G}/{|G|}$.
  \item $V$ is the view vector, calculated by simply negating each component of the given ray vector.
  \item $R$ is the reflection vector, given by $R = (2N \cdot L)N-L$.
\end{itemize}

\noindent To emphasize the material color, we chose $I_a = I_l$. For the parameters $k_a$, $k_d$, $k_s$ and $\alpha$ we found the values suggested in the assignment to be suitable: 0.1, 0.7, 0.2 and 100 respectively.

\autoref{fig:phong} To show the effect of changing these parameters. The ambient parameter $k_a$ affects the amount of ambient light uniformly across the scene. The higher the value, the higher the intensity of ambient light. This can be seen by comparing \autoref{fig:phong} (a) and (b).

The diffuse parameter $k_d$ affects the intensity of the diffuse reflection. The higher the value, the brighter the subject appears. This can be seen by comparing \autoref{fig:phong} (a) and (c).

The specular component $k_s$ affects the intensity of the specular reflection. The higher the value, the more glaring the reflection. This can be seen by comparing \autoref{fig:phong} (a) and (d).

The implementation can be found in the method {\tt computePhongShading}. This method is called from both {\tt traceRayIso} and {\tt traceRayComposite} when shading is enabled.

\subsection{2D transfer functions}

\paragraph{Isovalue contour surfaces}

The previously shown rendering methods are effective in certain situations, but they do not always allow uniquely identifying a feature of interest. By incorporating gradient information in the transfer function, we provide another tool to visualize these features.

We apply the method described by Levoy\citep{levoy_1988} to compute a voxel opacity:

\begin{equation*}
\alpha(\vb{x_i}) = \alpha_v
\begin{cases}
  1 &\text{if}\;|\grad f(\vb{x_i})| = 0\;\text{and}\\
  &\quad f(\vb{x_i} = f_v)\\
  1 - \dfrac{1}{r} \left| \dfrac{f_v - f(\vb{x_i})}{|\grad f(\vb{x_i})|}\right| &\text{if}\; |\grad f(\vb{x_i})| > 0\;\text{and}\;\\
  &\quad f(\vb{x_i}) - r\; |\grad f(\vb{x_i})| \leq f_v \leq\\
  &\quad f(\vb{x_i}) + r\; |\grad f(\vb{x_i})|\\
  0 &\text{otherwise}
\end{cases}
\end{equation*}

While the isosurface raycasting method described in \autoref{subsec:isosurface} renders all voxels with a value larger than or equal to $f_v$ as fully opaque, the method presented here also assigns a non-zero opacity $\alpha(\vb{x_i})$ to voxels that have values $f(\vb{x_i})$ that are close to $f_v$. The rate at which this opacity falls off is inversely proportional to the user-specified radius $r$ and the magnitude of the gradient $\grad f(\vb{x_i})$. In addition, the opacity is scaled by a constant $\alpha_v$.

The parameters of the 2D transfer function can be configured through the graphical interface shown in \autoref{fig:2dtf}. Here, the intensity field defines $f_v$ and is graphically represented by the median of the triangle. The radius $r$ determines the width of the triangle. The opacity field defines $\alpha_v$. \autoref{fig:2dtf} also shows how different transfer functions may be used to highlight features with different intensity values.

Some bigger datasets can cause a delay of 1-3 seconds when rendering the image between changes of parameters.

The code implementing the opacity computation can be found in the method {\tt computeOpacity2DTF}.

\subparagraph{Isosurface raycasting vs 2D transfer function}

When comparing isosurface raycasting in \autoref{fig:carp-skelet} and the 2D transfer function in \autoref{fig:2dtf} (b) we can clearly see that the latter produces a more detailed view of the fish skeleton due to the way voxels with higher and lower intensity are given different opacities. But if we focus on some details, for example the small bones on the spine of the carp, we notice that they are better seen on \autoref{fig:carp-skelet} because the isosurface raycasting approach produces sharper edges.

\subsection{Cutting plane}

The user can choose to use a different rendering method or parameters for two halves of the volume, separated by a so called cutting plane. To achieve this, we start by determining on which side of the plane the entry and exit points are located. For that, we first calculate the difference between the point ($p$) and the plane point ($P_p$). With the obtained vector, we calculate the dot product with the plane normal ($P_N$):

$$(p-P_p)\cdot P_N$$

We considered that, if the resulting value is larger than 0, then the point is on the back side. Otherwise, it would be on the other side. By knowing in which side of the cutting plane both entry and exit points are located, we can now render the volumes according to some rules.

If the entry and exit points are both on the \textbf{same side} of the cutting plane, we render the volume using the rendering function corresponding to that side, from the entry to the exit point.

In case the entry and exit points are on \textbf{different sides} of the cutting plane, we first calculate the intersection of the line segment defined by both points with the cutting plane. For that, we use the function {\tt intersectFace}. Then, we render the volume using the rendering function from the side where the entry point is on, from the entry point to the intersection point.

Finally, if the entry and exit points are on different sides, and the rendering function did not render anything on the ray from the entry to the intersection point (the opacity of all voxels was $0$), then we can ``see through" that point so we need to render the other side. To correctly implement that, we now render the half-ray from the intersection point to the exit point, using the corresponding rendering function.

\autoref{fig:cutplane} shows how the feature works. In (a) using compositing on one side, while the other remains invisible. This allows to see the insides of the volume. In (b) you can see two sides rendered with different methods, in this case MIP and isosurface.

In addition to the implementation in the {\tt raycast} method, we also added a boolean parameter to the methods {\tt traceRayComposite} and {\tt traceRayIso} to determine  which half of the volume we are rendering.

\subsection{Results}

After implementing all functions we tried different datasets and some interesting results will be shown in this section.

In \autoref{fig:backpack-mip} we can see the \textit{backpack8\_small} dataset visualized using MIP. The items inside the backpack are visible and can be easily distinguished, because they have higher intensity than the surrounding material. As an example, this method could be useful to airport security.

Another interesting feature is shown in \autoref{fig:carp-skelet} where the skeleton of a carp is visualized using isosurface raycasting. This method is particularly useful for visualizing material with very high intensities, such as bones.

Rendering using the 2D transfer function on the \textit{tooth} dataset can be observed on \autoref{fig:tooth}. The tooth's outline can be seen together with the pulp chamber inside of it.

\section{Conclusions}

TODO!!!

\bibliographystyle{plain}
\bibliography{references}

\pagebreak
\appendix
\section{Figures}

\begin{figure}[h]
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth]{trilinear-off}
    \caption{Trilinear interpolation disabled.}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth]{trilinear-on}
    \caption{Trilinear interpolation enabled.}
  \end{subfigure}
  \caption{Result of compositing visualization with and without trilinear interpolation on the \textit{orange} dataset.}
  \label{fig:trilinear}
\end{figure}

\begin{figure}[h]
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth]{before-speedup}
    \caption{Interactive mode before speed up changes. Rendering time: 7295 ms }
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth]{after-speedup}
    \caption{Interactive mode after speed up changes. Rendering time 816 ms}
  \end{subfigure}
  \caption{Result of speeding up interactive mode on the \textit{orange} dataset.}
  \label{fig:speedup}
\end{figure}

\begin{figure}[h]
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth]{orange-composite}
    \caption{Composite with default values.}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth]{orange-mips}
    \caption{MIP with default values.}
  \end{subfigure}
  \caption{Comparison of different raycasting techniques on \textit{orange} dataset.}
  \label{fig:mipscomp}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\textwidth]{iso-surface}
  \caption{Isosurface raycasting without shading enabled on \textit{carp8} dataset.}
  \label{fig:isosurface}
\end{figure}

\begin{figure}[h]
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth]{pig8-phong-default}
    \caption{Default values.}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth]{pig8-phong-ambient05}
    \caption{Ambient $k_a=0.5$, higher than the default.}
  \end{subfigure}
  \\~\\
  \begin{subfigure}[b]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth]{pig8-phong-diffuse02}
    \caption{Diffuse $k_d=0.2$, lower than the default.}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth]{pig8-phong-specular0}
    \caption{Specular $k_s=0.0$, lower than the default.}
  \end{subfigure}
  \caption{Comparison of the effect of changing different parameters of Phong's shading on \textit{pig8} dataset.}
  \label{fig:phong}
\end{figure}

\begin{figure}[h]
  \centering
  \begin{subfigure}[b]{\textwidth}
    \includegraphics[width=\textwidth]{2dtf}
    \caption{A transfer function revealing lower density features.}
  \end{subfigure}
  \\~\\
  \begin{subfigure}[b]{\textwidth}
    \includegraphics[width=\textwidth]{2dtf-skeleton}
    \caption{A transfer function revealing higher density features.}
  \end{subfigure}
  \caption{Comparison of different 2-D transfer functions on \textit{carp8} dataset.}
  \label{fig:2dtf}
\end{figure}

\begin{figure}[h]
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth]{pig8-cut-plane-coins}
    \caption{Composite with cutting plane. Inside of the volume is visible.}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth]{pig8-cut-plane-renders}
    \caption{MIP and isosurface with shading. Each side of the volume is rendered differently.}
  \end{subfigure}
  \caption{Cutting plane demonstration with \textit{pig8} dataset.}
  \label{fig:cutplane}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\textwidth]{backpack-MIP}
  \caption{MIP on \textit{backpack8\_small} dataset with inside volume visible.}
  \label{fig:backpack-mip}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\textwidth]{carp-iso-180}
  \caption{Isosurface raycasting with isovalue 180 on \textit{carp8} dataset.}
  \label{fig:carp-skelet}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\textwidth]{tooth-2d}
  \caption{The 2D transfer function rendering method on \textit{tooth} dataset with pulp chamber visible. The parameters used are `$f_v$ = 720`, `r = 460`, `$\alpha_v$ = 0.3`.}
  \label{fig:tooth}
\end{figure}

\end{document}
