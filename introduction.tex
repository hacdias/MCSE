Machine Learning (ML) has revolutionized the way we think and work with data, opening way to new techniques and explorations. ML models can be powerful tools to predict things that would otherwise require high amounts of effort, either human or computational. As an example, we can think about image recognition in healthcare that can help medical professionals diagnose disorders. Another example could be smart watch sensor data that can help train models to detect abnormal heart rates or walking patterns. Even though models such as these can be very helpful, they have to be trained with high amounts of good quality data in order for the model to perform accurately \cite{10.1145/3394486.3406477}. To address this issues, there are techniques that allow multiple parties to collaboratively train the same models.

In 2016, Google researchers attempted to build communication-efficient deep neural networks in decentralized data settings. The result of this work was the introduction of a new way of collaboratively training Machine Learning models, which they termed Federated Learning \cite{10.48550/arxiv.1602.05629}. Federated Learning (FL) allows multiple clients, in different locations, to cooperate on the same Machine Learning model without sharing their own data with each other. Instead of sharing the raw data, clients only share model parameters, such as weights. Both of this aspects bring some benefits. The first benefit is that, by not sharing raw data, models can preserve data privacy, allowing them to be trained on sensitive data. In addition, since model parameters are usually much smaller than the raw data, this also leads to less data being transported over the networks. Finally, since the data is distributed among different devices, a single powerful device is not required to train the model, as usually training models with smaller amounts of data is less computationally expensive.

Currently, most FL networks include a central server that coordinates the entire process and aggregates the model eights from each of the clients into a single model. This central coordinator is a single point of failure in the network, since it is always required to be online and behave correctly \cite{li_blockchain_2021, 10.48550/arxiv.2110.02182}. To address this, Blockchain-based Federated Learning techniques have been proposed. The following are some aspects and properties that Blockchain can bring to Federated Learning when combined:

\begin{itemize}
    \item \textit{Traceability and Auditability}. Due to the structure of the blockchain, it is possible to trace transactions to their original source, which can be useful for auditability purposes \cite{10.48550/arxiv.1902.01046, 10.48550/arxiv.2110.02182}.
    
    \item \textit{Data Immutability and Persistency}. Once transactions are added to the distributed ledger, it is nearly impossible to revert them or change their information \cite{10.48550/arxiv.1902.01046, qu_blockchain-enabled_2022}. This ensures that data is not changed and it can be retrieved after the fact.
    
    \item \textit{Decentralization}. The involvement of a central orchestrator is eliminated and the processing of the aggregation is replaced by multiple servers \cite{10.48550/arxiv.2009.09338, 9403374, 10.48550/arxiv.2110.02182, qu_blockchain-enabled_2022}. This improves the resilience and availability of the system.
    
    \item \textit{Authentication}. Blockchain ensures the authentication of data and messages due to the verification mechanisms in place, such as the usage of private keys to sign transactions \cite{qu_blockchain-enabled_2022}.
\end{itemize}

\section{Motivation}\label{intro:motivation}

In Blockchain-based Federated Learning, there are certain aspects to take into account that influence the outcome of the learning process, as well as the resources consumed to reach that point. With Federated Learning being increasingly adopted in IoT networks, where low powered devices with low resources are the norm, it is important to ensure that certain aspects of the system, as well as new techniques, consume the least amount of resources.

One of the most impactful aspects of blockchain networks is the consensus algorithms, which can lead to very different resource consumption \cite{ccaf}, as well as different degrees of latency \cite{Alqahtani_2021}. Two other important aspects in Blockchain-based Federated Learning systems are the participant selection techniques and the scoring techniques. While the former indicates how the participants are chosen in each round, the latter aids on scoring each client's submissions in order to identify which ones are the best and should be included in the final aggregation. All this algorithms and techniques influence the accuracy, convergence and resource consumption. At the same time, they are influenced by the number of devices participating in the network, and also by the degrees of privacy

\section{Problem Statement}\label{intro:problem}

Motivated by the lack of any open-source framework for Blockchain-based Federated Learning, this thesis first focuses on designing and implementing the first open-source modular framework for Blockchain-based Federated Learning using Ethereum and TensorFlow. This framework can be easily adapted to support multiple architectures, as well as different techniques, whether it be for participant selection, or for scoring, or for aggregation. In addition, this framework should also support multiple types of data partition, such as horizontal and vertical.

With the framework designed and implemented, we will then compare different aspects and techniques of Blockchain-based Federated Learning in terms of execution time, convergence, accuracy, communication and computation costs. This will allow us to identify which techniques or combination of techniques and properties are more adequate in different scenarios. For example, we will be able to identify which techniques are more adequate for resource constricted networks, whether it be low bandwidth devices, or low computation power devices. Another example would be a scenario where we need to identify which scoring technique is the least affected by a high degree of privacy.

\section{Research Questions}\label{intro:questions}

Taking into account the motivation and problem statement, this work will focus on answering the following main research question:

\begin{center}
    \textit{What is the impact of different Blockchain-based Federated Learning properties and techniques on execution time, convergence and accuracy, as well as communication and computation costs?}
\end{center}

This research question can be further sub-divided into four sub-questions to aid addressing specific points of the research:

\begin{enumerate}
    \item \textit{How to design a modular framework that allows to easily customize different aspects of Blockchain-based Federated Learning?}
    
    \item \textit{How do consensus algorithms, participant selection techniques and scoring techniques influence execution time, convergence, accuracy, and communication and computation costs?}
    
    \item \textit{How does the number of training devices, as well as degrees of privacy impact the different scoring mechanisms?}
    
    \item \textit{How can we build a Blockchain-based Federated Learning framework that supports different data partition formats, such as vertical and horizontal?}
\end{enumerate}

\section{Outline}\label{intro:outline}

The remainder of the thesis is structured as follows. \Cref{chapter:related_work} reviews the existing work regarding aspects and techniques used in Blockchain-based Federated Learning systems. \Cref{chapter:background} provides definitions and fundamental concepts about the system, as well as background information on the aspects and techniques that will be explored. \Cref{chapter:methodology} goes over the design and methodology of the experiment. \Cref{chapter:implementation} provides details about the implementation of the experiment. \Cref{chapter:evaluation} provides information regarding the experimental setup of the experiments. Chapters \ref{chapter:analysis:consensus_algorithms}, \ref{chapter:analysis:participants}, \ref{chapter:analysis:scoring}, \ref{chapter:analysis:clients}, \ref{chapter:analysis:privacy} provide the analysis on the impacts of consensus algorithms, participant selection techniques, scoring techniques, training clients and privacy degrees, respectively. \Cref{chapter:vertical} provides analysis of the proof of concept of Vertical Federated Learning applied in a Blockchain-based Federated Learning system. Finally, \cref{chapter:conclusion} discusses the results, contributions and provides directions for future works.

