@article{8894364,
	title        = {DeepChain: Auditable and Privacy-Preserving Deep Learning with Blockchain-Based Incentive},
	author       = {Weng, Jiasi and Weng, Jian and Zhang, Jilian and Li, Ming and Zhang, Yue and Luo, Weiqi},
	year         = 2021,
	journal      = {IEEE Transactions on Dependable and Secure Computing},
	volume       = 18,
	number       = 5,
	pages        = {2438--2455},
	doi          = {10.1109/TDSC.2019.2952332}
}
@article{lecun2010mnist,
	title        = {MNIST handwritten digit database},
	author       = {LeCun, Yann and Cortes, Corinna and Burges, CJ},
	year         = 2010,
	journal      = {ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},
	volume       = 2
}
@techreport{Krizhevsky09learningmultiple,
	title        = {Learning multiple layers of features from tiny images},
	author       = {Alex Krizhevsky},
	year         = 2009,
	institution  = {}
}
@article{9293091,
	title        = {A Blockchain-Based Decentralized Federated Learning Framework with Committee Consensus},
	author       = {Li, Yuzheng and Chen, Chuan and Liu, Nan and Huang, Huawei and Zheng, Zibin and Yan, Qiang},
	year         = 2021,
	journal      = {IEEE Network},
	volume       = 35,
	number       = 1,
	pages        = {234--241},
	doi          = {10.1109/MNET.011.2000263}
}
@article{app8122663,
	title        = {Chained Anomaly Detection Models for Federated Learning: An Intrusion Detection Case Study},
	author       = {Preuveneers, Davy and Rimmer, Vera and Tsingenopoulos, Ilias and Spooren, Jan and Joosen, Wouter and Ilie-Zudor, Elisabeth},
	year         = 2018,
	journal      = {Applied Sciences},
	volume       = 8,
	number       = 12,
	doi          = {10.3390/app8122663},
	issn         = {2076-3417},
	url          = {https://www.mdpi.com/2076-3417/8/12/2663},
	article-number = 2663,
	abstract     = {The adoption of machine learning and deep learning is on the rise in the cybersecurity domain where these AI methods help strengthen traditional system monitoring and threat detection solutions. However, adversaries too are becoming more effective in concealing malicious behavior amongst large amounts of benign behavior data. To address the increasing time-to-detection of these stealthy attacks, interconnected and federated learning systems can improve the detection of malicious behavior by joining forces and pooling together monitoring data. The major challenge that we address in this work is that in a federated learning setup, an adversary has many more opportunities to poison one of the local machine learning models with malicious training samples, thereby influencing the outcome of the federated learning and evading detection. We present a solution where contributing parties in federated learning can be held accountable and have their model updates audited. We describe a permissioned blockchain-based federated learning method where incremental updates to an anomaly detection machine learning model are chained together on the distributed ledger. By integrating federated learning with blockchain technology, our solution supports the auditing of machine learning models without the necessity to centralize the training data. Experiments with a realistic intrusion detection use case and an autoencoder for anomaly detection illustrate that the increased complexity caused by blockchain technology has a limited performance impact on the federated learning, varying between 5 and 15\%, while providing full transparency over the distributed training process of the neural network. Furthermore, our blockchain-based federated learning solution can be generalized and applied to more sophisticated neural network architectures and other use cases.}
}
@misc{10.48550/arxiv.2007.03856,
	title        = {BlockFLow: An Accountable and Privacy-Preserving Solution for Federated Learning},
	author       = {Mugunthan, Vaikkunth and Rahman, Ravi and Kagal, Lalana},
	year         = 2020,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.2007.03856},
	url          = {https://arxiv.org/abs/2007.03856},
	copyright    = {arXiv.org perpetual, non-exclusive license},
	keywords     = {Machine Learning (cs.LG), Cryptography and Security (cs.CR), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences}
}
@inproceedings{9274451,
	title        = {Chain FL: Decentralized Federated Machine Learning via Blockchain},
	author       = {Korkmaz, Caner and Kocas, Halil Eralp and Uysal, Ahmet and Masry, Ahmed and Ozkasap, Oznur and Akgun, Baris},
	year         = 2020,
	booktitle    = {2020 Second International Conference on Blockchain Computing and Applications (BCCA)},
	volume       = {},
	number       = {},
	pages        = {140--146},
	doi          = {10.1109/BCCA50787.2020.9274451}
}
@inproceedings{baffle,
	title        = {BAFFLE : Blockchain Based Aggregator Free Federated Learning},
	author       = {Ramanan, Paritosh and Nakayama, Kiyoshi},
	year         = 2020,
	booktitle    = {2020 IEEE International Conference on Blockchain (Blockchain)},
	volume       = {},
	number       = {},
	pages        = {72--81},
	doi          = {10.1109/Blockchain50366.2020.00017}
}
@inproceedings{demo,
	title        = {Demo: A Blockchain Based Protocol for Federated Learning},
	author       = {Zhang, Qiong and Palacharla, Paparao and Sekiya, Motoyoshi and Suga, Junichi and Katagiri, Toru},
	year         = 2020,
	booktitle    = {2020 IEEE 28th International Conference on Network Protocols (ICNP)},
	volume       = {},
	number       = {},
	pages        = {1--2},
	doi          = {10.1109/ICNP49622.2020.9259388}
}
@inproceedings{8945913,
	title        = {Record and Reward Federated Learning Contributions with Blockchain},
	author       = {Martinez, Ismael and Francis, Sreya and Hafid, Abdelhakim Senhaji},
	year         = 2019,
	booktitle    = {2019 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery (CyberC)},
	volume       = {},
	number       = {},
	pages        = {50--57},
	doi          = {10.1109/CyberC.2019.00018}
}
@article{8733825,
	title        = {Blockchained On-Device Federated Learning},
	author       = {Kim, Hyesung and Park, Jihong and Bennis, Mehdi and Kim, Seong-Lyun},
	year         = 2020,
	journal      = {IEEE Communications Letters},
	volume       = 24,
	number       = 6,
	pages        = {1279--1283},
	doi          = {10.1109/LCOMM.2019.2921755}
}
@article{8843900,
	title        = {Blockchain and Federated Learning for Privacy-Preserved Data Sharing in Industrial IoT},
	author       = {Lu, Yunlong and Huang, Xiaohong and Dai, Yueyue and Maharjan, Sabita and Zhang, Yan},
	year         = 2020,
	journal      = {IEEE Transactions on Industrial Informatics},
	volume       = 16,
	number       = 6,
	pages        = {4177--4186},
	doi          = {10.1109/TII.2019.2942190}
}
@article{9524833,
	title        = {Toward On-Device Federated Learning: A Direct Acyclic Graph-Based Blockchain Approach},
	author       = {Cao, Mingrui and Zhang, Long and Cao, Bin},
	year         = 2021,
	journal      = {IEEE Transactions on Neural Networks and Learning Systems},
	volume       = {},
	number       = {},
	pages        = {1--15},
	doi          = {10.1109/TNNLS.2021.3105810}
}
@article{8832210,
	title        = {Incentive Mechanism for Reliable Federated Learning: A Joint Optimization Approach to Combining Reputation and Contract Theory},
	author       = {Kang, Jiawen and Xiong, Zehui and Niyato, Dusit and Xie, Shengli and Zhang, Junshan},
	year         = 2019,
	journal      = {IEEE Internet of Things Journal},
	volume       = 6,
	number       = 6,
	pages        = {10700--10714},
	doi          = {10.1109/JIOT.2019.2940820}
}
@article{9292450,
	title        = {Biscotti: A Blockchain System for Private and Secure Federated Learning},
	author       = {Shayan, Muhammad and Fung, Clement and Yoon, Chris J. M. and Beschastnikh, Ivan},
	year         = 2021,
	journal      = {IEEE Transactions on Parallel and Distributed Systems},
	volume       = 32,
	number       = 7,
	pages        = {1513--1525},
	doi          = {10.1109/TPDS.2020.3044223}
}
@misc{pirate,
	title        = {PIRATE: A Blockchain-based Secure Framework of Distributed Machine Learning in 5G Networks},
	author       = {Zhou, Sicong and Huang, Huawei and Chen, Wuhui and Zheng, Zibin and Guo, Song},
	year         = 2019,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.1912.07860},
	url          = {https://arxiv.org/abs/1912.07860},
	copyright    = {arXiv.org perpetual, non-exclusive license},
	keywords     = {Distributed, Parallel, and Cluster Computing (cs.DC), Cryptography and Security (cs.CR), FOS: Computer and information sciences, FOS: Computer and information sciences}
}
@misc{10.48550/arxiv.1912.04859,
	title        = {Privacy-Preserving Blockchain Based Federated Learning with Differential Data Sharing},
	author       = {Nagar, Anudit},
	year         = 2019,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.1912.04859},
	url          = {https://arxiv.org/abs/1912.04859},
	copyright    = {arXiv.org perpetual, non-exclusive license},
	keywords     = {Cryptography and Security (cs.CR), Distributed, Parallel, and Cluster Computing (cs.DC), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences}
}
@article{8998397,
	title        = {Blockchain Empowered Asynchronous Federated Learning for Secure Data Sharing in Internet of Vehicles},
	author       = {Lu, Yunlong and Huang, Xiaohong and Zhang, Ke and Maharjan, Sabita and Zhang, Yan},
	year         = 2020,
	journal      = {IEEE Transactions on Vehicular Technology},
	volume       = 69,
	number       = 4,
	pages        = {4298--4311},
	doi          = {10.1109/TVT.2020.2973651}
}
@article{9079513,
	title        = {Federated Learning With Blockchain for Autonomous Vehicles: Analysis and Design Challenges},
	author       = {Pokhrel, Shiva Raj and Choi, Jinho},
	year         = 2020,
	journal      = {IEEE Transactions on Communications},
	volume       = 68,
	number       = 8,
	pages        = {4734--4746},
	doi          = {10.1109/TCOMM.2020.2990686}
}
@article{9127823,
	title        = {A Hierarchical Blockchain-Enabled Federated Learning Algorithm for Knowledge Sharing in Internet of Vehicles},
	author       = {Chai, Haoye and Leng, Supeng and Chen, Yijin and Zhang, Ke},
	year         = 2021,
	journal      = {IEEE Transactions on Intelligent Transportation Systems},
	volume       = 22,
	number       = 7,
	pages        = {3975--3986},
	doi          = {10.1109/TITS.2020.3002712}
}
@article{9210531,
	title        = {Exploiting Unintended Property Leakage in Blockchain-Assisted Federated Learning for Intelligent Edge Computing},
	author       = {Shen, Meng and Wang, Huan and Zhang, Bin and Zhu, Liehuang and Xu, Ke and Li, Qi and Du, Xiaojiang},
	year         = 2021,
	journal      = {IEEE Internet of Things Journal},
	volume       = 8,
	number       = 4,
	pages        = {2265--2275},
	doi          = {10.1109/JIOT.2020.3028110}
}
@article{9233457,
	title        = {Blockchain-Based Federated Learning for Device Failure Detection in Industrial IoT},
	author       = {Zhang, Weishan and Lu, Qinghua and Yu, Qiuyu and Li, Zhaotong and Liu, Yue and Lo, Sin Kit and Chen, Shiping and Xu, Xiwei and Zhu, Liming},
	year         = 2021,
	journal      = {IEEE Internet of Things Journal},
	volume       = 8,
	number       = 7,
	pages        = {5926--5937},
	doi          = {10.1109/JIOT.2020.3032544}
}
@inproceedings{8905038,
	title        = {FLChain: A Blockchain for Auditable Federated Learning with Trust and Incentive},
	author       = {Bao, Xianglin and Su, Cheng and Xiong, Yan and Huang, Wenchao and Hu, Yifei},
	year         = 2019,
	booktitle    = {2019 5th International Conference on Big Data Computing and Communications (BIGCOM)},
	volume       = {},
	number       = {},
	pages        = {151--159},
	doi          = {10.1109/BIGCOM.2019.00030}
}
@article{FANG20221,
	title        = {A privacy-preserving and verifiable federated learning method based on blockchain},
	author       = {Chen Fang and Yuanbo Guo and Jiali Ma and Haodong Xie and Yifeng Wang},
	year         = 2022,
	journal      = {Computer Communications},
	volume       = 186,
	pages        = {1--11},
	doi          = {https://doi.org/10.1016/j.comcom.2022.01.002},
	issn         = {0140-3664},
	url          = {https://www.sciencedirect.com/science/article/pii/S0140366422000081},
	keywords     = {Federated learning, Blockchain, Verifiable secret sharing, Polynomial commitment, Tampering attack},
	abstract     = {As a novel distributed learning mechanism, federated learning has drawn widespread attention by allowing multiple parties to train an accurate model collaboratively without collecting their raw data. However, it relies on a trustworthy central server that still suffers from severe security challenges, such as model inversion attack and single point of failure. Thereby, a privacy-preserving and verifiable federated learning method based on blockchain is proposed to enable fully decentralized and reliable federated learning in untrusted network. In our scheme, we propose a secure aggregation protocol to guarantee the confidentiality of gradients while supporting clients dropping out during the workflow, and design a novel blockchain structure enabling global gradient verification to defend against potential tampering attack. In addition, a gradient compression method is proposed to reduce the communication overhead. Security analysis shows that our scheme can preserve the privacy by adding pairwise random masks to the gradients, and prevent Sybil attack by reasonable threshold setting in verifiable secret sharing. Experimental results on two real-world datasets illustrate that when the clients’ dropout rate is less than 20\%, our scheme can achieve almost the same accuracy as original federated learning, and performs better than similar blockchain-based federated learning methods in terms of computation overhead and communication overhead.}
}
@misc{10.48550/arxiv.2112.07938,
	title        = {Blockchain-enabled Server-less Federated Learning},
	author       = {Wilhelmi, Francesc and Giupponi, Lorenza and Dini, Paolo},
	year         = 2021,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.2112.07938},
	url          = {https://arxiv.org/abs/2112.07938},
	copyright    = {Creative Commons Attribution 4.0 International},
	keywords     = {Machine Learning (cs.LG), Distributed, Parallel, and Cluster Computing (cs.DC), Networking and Internet Architecture (cs.NI), FOS: Computer and information sciences, FOS: Computer and information sciences}
}
@misc{10.48550/arxiv.2101.03300,
	title        = {Robust Blockchained Federated Learning with Model Validation and Proof-of-Stake Inspired Consensus},
	author       = {Chen, Hang and Asif, Syed Ali and Park, Jihong and Shen, Chien-Chung and Bennis, Mehdi},
	year         = 2021,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.2101.03300},
	url          = {https://arxiv.org/abs/2101.03300},
	copyright    = {arXiv.org perpetual, non-exclusive license},
	keywords     = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Cryptography and Security (cs.CR), Distributed, Parallel, and Cluster Computing (cs.DC), Networking and Internet Architecture (cs.NI), FOS: Computer and information sciences, FOS: Computer and information sciences}
}
@article{9159643,
	title        = {CREAT: Blockchain-assisted Compression Algorithm of Federated Learning for Content Caching in Edge Computing},
	author       = {Cui, Laizhong and Su, Xiaoxin and Ming, Zhongxing and Chen, Ziteng and Yang, Shu and Zhou, Yipeng and Xiao, Wei},
	year         = 2020,
	journal      = {IEEE Internet of Things Journal},
	volume       = {},
	number       = {},
	pages        = {1--1},
	doi          = {10.1109/JIOT.2020.3014370}
}
@article{9134967,
	title        = {A Blockchained Federated Learning Framework for Cognitive Computing in Industry 4.0 Networks},
	author       = {Qu, Youyang and Pokhrel, Shiva Raj and Garg, Sahil and Gao, Longxiang and Xiang, Yong},
	year         = 2021,
	journal      = {IEEE Transactions on Industrial Informatics},
	volume       = 17,
	number       = 4,
	pages        = {2964--2973},
	doi          = {10.1109/TII.2020.3007817}
}
@article{9170559,
	title        = {Privacy-Preserving Blockchain-Based Federated Learning for IoT Devices},
	author       = {Zhao, Yang and Zhao, Jun and Jiang, Linshan and Tan, Rui and Niyato, Dusit and Li, Zengxiang and Lyu, Lingjuan and Liu, Yingbo},
	year         = 2021,
	journal      = {IEEE Internet of Things Journal},
	volume       = 8,
	number       = 3,
	pages        = {1817--1829},
	doi          = {10.1109/JIOT.2020.3017377}
}
@article{9311394,
	title        = {Blockchain and Federated Learning for 5G Beyond},
	author       = {Lu, Yunlong and Huang, Xiaohong and Zhang, Ke and Maharjan, Sabita and Zhang, Yan},
	year         = 2021,
	journal      = {IEEE Network},
	volume       = 35,
	number       = 1,
	pages        = {219--225},
	doi          = {10.1109/MNET.011.1900598}
}
@article{9223754,
	title        = {Hybrid Blockchain-Based Resource Trading System for Federated Learning in Edge Computing},
	author       = {Fan, Sizheng and Zhang, Hongbo and Zeng, Yuchen and Cai, Wei},
	year         = 2021,
	journal      = {IEEE Internet of Things Journal},
	volume       = 8,
	number       = 4,
	pages        = {2252--2264},
	doi          = {10.1109/JIOT.2020.3028101}
}
@article{9399813,
	title        = {BAFL: A Blockchain-Based Asynchronous Federated Learning Framework},
	author       = {Feng, Lei and Zhao, Yiqi and Guo, Shaoyong and Qiu, Xuesong and Li, Wenjing and Yu, Peng},
	year         = 2022,
	journal      = {IEEE Transactions on Computers},
	volume       = 71,
	number       = 5,
	pages        = {1092--1103},
	doi          = {10.1109/TC.2021.3072033}
}
@article{9170905,
	title        = {Low-Latency Federated Learning and Blockchain for Edge Association in Digital Twin Empowered 6G Networks},
	author       = {Lu, Yunlong and Huang, Xiaohong and Zhang, Ke and Maharjan, Sabita and Zhang, Yan},
	year         = 2021,
	journal      = {IEEE Transactions on Industrial Informatics},
	volume       = 17,
	number       = 7,
	pages        = {5098--5107},
	doi          = {10.1109/TII.2020.3017668}
}
@article{9347812,
	title        = {Proof of Federated Learning: A Novel Energy-Recycling Consensus Algorithm},
	author       = {Qu, Xidi and Wang, Shengling and Hu, Qin and Cheng, Xiuzhen},
	year         = 2021,
	journal      = {IEEE Transactions on Parallel and Distributed Systems},
	volume       = 32,
	number       = 8,
	pages        = {2074--2085},
	doi          = {10.1109/TPDS.2021.3056773}
}
@article{9321132,
	title        = {VFChain: Enabling Verifiable and Auditable Federated Learning via Blockchain Systems},
	author       = {Peng, Zhe and Xu, Jianliang and Chu, Xiaowen and Gao, Shang and Yao, Yuan and Gu, Rong and Tang, Yuzhe},
	year         = 2022,
	journal      = {IEEE Transactions on Network Science and Engineering},
	volume       = 9,
	number       = 1,
	pages        = {173--186},
	doi          = {10.1109/TNSE.2021.3050781}
}
@article{8994206,
	title        = {Reliable Federated Learning for Mobile Networks},
	author       = {Kang, Jiawen and Xiong, Zehui and Niyato, Dusit and Zou, Yuze and Zhang, Yang and Guizani, Mohsen},
	year         = 2020,
	journal      = {IEEE Wireless Communications},
	volume       = 27,
	number       = 2,
	pages        = {72--80},
	doi          = {10.1109/MWC.001.1900119}
}
@article{9184854,
	title        = {Blockchain-Based Federated Learning for Intelligent Control in Heavy Haul Railway},
	author       = {Hua, Gaofeng and Zhu, Li and Wu, Jinsong and Shen, Chunzi and Zhou, Linyan and Lin, Qingqing},
	year         = 2020,
	journal      = {IEEE Access},
	volume       = 8,
	number       = {},
	pages        = {176830--176839},
	doi          = {10.1109/ACCESS.2020.3021253}
}
@inproceedings{8893114,
	title        = {Blockchain-based Node-aware Dynamic Weighting Methods for Improving Federated Learning Performance},
	author       = {Kim, You Jun and Hong, Choong Seon},
	year         = 2019,
	booktitle    = {2019 20th Asia-Pacific Network Operations and Management Symposium (APNOMS)},
	volume       = {},
	number       = {},
	pages        = {1--4},
	doi          = {10.23919/APNOMS.2019.8893114}
}
@inproceedings{9006344,
	title        = {Mechanism Design for An Incentive-aware Blockchain-enabled Federated Learning Platform},
	author       = {Toyoda, Kentaroh and Zhang, Allan N.},
	year         = 2019,
	booktitle    = {2019 IEEE International Conference on Big Data (Big Data)},
	volume       = {},
	number       = {},
	pages        = {395--403},
	doi          = {10.1109/BigData47090.2019.9006344}
}
@inproceedings{10.1145/3422337.3447837,
	title        = {BlockFLA: Accountable Federated Learning via Hybrid Blockchain Architecture},
	author       = {Desai, Harsh Bimal and Ozdayi, Mustafa Safa and Kantarcioglu, Murat},
	year         = 2021,
	booktitle    = {Proceedings of the Eleventh ACM Conference on Data and Application Security and Privacy},
	location     = {Virtual Event, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CODASPY '21},
	pages        = {101–112},
	doi          = {10.1145/3422337.3447837},
	isbn         = 9781450381437,
	url          = {https://doi.org/10.1145/3422337.3447837},
	abstract     = {Federated Learning (FL) is a distributed, and decentralized machine learning protocol. By executing FL, a set of agents can jointly train a model without sharing their datasets with each other, or a third-party. This makes FL particularly suitable for settings where data privacy is desired.At the same time, concealing training data gives attackers an opportunity to inject backdoors into the trained model. It has been shown that an attacker can inject backdoors to the trained model during FL, and then can leverage the backdoor to make the model misclassify later. Several works tried to alleviate this threat by designing robust aggregation functions. However, given more sophisticated attacks are developed over time, which by-pass the existing defenses, we approach this problem from a complementary angle in this work. Particularly, we aim to discourage backdoor attacks by detecting, and punishing the attackers, possibly after the end of training phase.To this end, we develop a hybrid blockchain-based FL framework that uses smart contracts to automatically detect, and punish the attackers via monetary penalties. Our framework is general in the sense that, any aggregation function, and any attacker detection algorithm can be plugged into it. We conduct experiments to demonstrate that our framework preserves the communication-efficient nature of FL, and provide empirical results to illustrate that it can successfully penalize attackers by leveraging our novel attacker detection algorithm.},
	numpages     = 12,
	keywords     = {federated averaging, hyperledger, backdoor attacks, machine learning, ethereum, federated learning, hybrid blockchain}
}
@misc{10.48550/arxiv.2009.09338,
	title        = {When Federated Learning Meets Blockchain: A New Distributed Learning Paradigm},
	author       = {Ma, Chuan and Li, Jun and Ding, Ming and Shi, Long and Wang, Taotao and Han, Zhu and Poor, H. Vincent},
	year         = 2020,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.2009.09338},
	url          = {https://arxiv.org/abs/2009.09338},
	copyright    = {arXiv.org perpetual, non-exclusive license},
	keywords     = {Networking and Internet Architecture (cs.NI), FOS: Computer and information sciences, FOS: Computer and information sciences}
}
@article{Peyvandi2022,
	title        = {Privacy-preserving federated learning for scalable and high data quality computational-intelligence-as-a-service in Society 5.0},
	author       = {Peyvandi, Amirhossein and Majidi, Babak and Peyvandi, Soodeh and Patra, Jagdish C.},
	year         = 2022,
	month        = {Mar},
	day          = 22,
	journal      = {Multimedia Tools and Applications},
	doi          = {10.1007/s11042-022-12900-5},
	issn         = {1573-7721},
	url          = {https://doi.org/10.1007/s11042-022-12900-5},
	abstract     = {Training supervised machine learning models like deep learning requires high-quality labelled datasets that contain enough samples from various categories and specific cases. The Data as a Service (DaaS) can provide this high-quality data for training efficient machine learning models. However, the issue of privacy can minimize the participation of the data owners in DaaS provision. In this paper, a blockchain-based decentralized federated learning framework for secure, scalable, and privacy-preserving computational intelligence, called Decentralized Computational Intelligence as a Service (DCIaaS), is proposed. The proposed framework is able to improve data quality, computational intelligence quality, data equality, and computational intelligence equality for complex machine learning tasks. The proposed framework uses the blockchain network for secure decentralized transfer and sharing of data and machine learning models on the cloud. As a case study for multimedia applications, the performance of DCIaaS framework for biomedical image classification and hazardous litter management is analysed. Experimental results show an increase in the accuracy of the models trained using the proposed framework compared to decentralized training. The proposed framework addresses the issue of privacy-preserving in DaaS using the distributed ledger technology and acts as a platform for crowdsourcing the training process of machine learning models.}
}
@misc{10.48550/arxiv.2202.02817,
	title        = {BEAS: Blockchain Enabled Asynchronous \& Secure Federated Machine Learning},
	author       = {Mondal, Arup and Virk, Harpreet and Gupta, Debayan},
	year         = 2022,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.2202.02817},
	url          = {https://arxiv.org/abs/2202.02817},
	copyright    = {Creative Commons Attribution 4.0 International},
	keywords     = {Cryptography and Security (cs.CR), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences}
}
@inproceedings{10.1145/3319535.3363256,
	title        = {Poster: A Reliable and Accountable Privacy-Preserving Federated Learning Framework Using the Blockchain},
	author       = {Awan, Sana and Li, Fengjun and Luo, Bo and Liu, Mei},
	year         = 2019,
	booktitle    = {Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security},
	location     = {London, United Kingdom},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CCS '19},
	pages        = {2561–2563},
	doi          = {10.1145/3319535.3363256},
	isbn         = 9781450367479,
	url          = {https://doi.org/10.1145/3319535.3363256},
	abstract     = {Federated learning (FL) is promising in supporting collaborative learning applications that involve large datasets, massively distributed data owners and unreliable network connectivity. To protect data privacy, existing FL approaches adopt (k,n)-threshold secret sharing schemes, based on the semi-honest assumption for clients, to enable secure multiparty computation in local model update exchange which deals with random client dropouts at the cost of increasing data size. These approaches adopt the semi-honest assumption for clients, therefore they are vulnerable to malicious clients. In this work, we propose a blockchain-based privacy-preserving federated learning (BC-based PPFL) framework, which leverages the immutability and decentralized trust properties of blockchain to provide provenance of model updates. Our proof-of-concept implementation of BC-based PPFL demonstrates it is practical for secure aggregation of local model updates in the federated setting.},
	numpages     = 3,
	keywords     = {federated learning, privacy, blockchain}
}
@inproceedings{8892848,
	title        = {FLchain: Federated Learning via MEC-enabled Blockchain Network},
	author       = {Majeed, Umer and Hong, Choong Seon},
	year         = 2019,
	booktitle    = {2019 20th Asia-Pacific Network Operations and Management Symposium (APNOMS)},
	volume       = {},
	number       = {},
	pages        = {1--4},
	doi          = {10.23919/APNOMS.2019.8892848}
}
@misc{10.48550/arxiv.1910.12603,
	title        = {A blockchain-orchestrated Federated Learning architecture for healthcare consortia},
	author       = {Passerat-Palmbach, Jonathan and Farnan, Tyler and Miller, Robert and Gross, Marielle S. and Flannery, Heather Leigh and Gleim, Bill},
	year         = 2019,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.1910.12603},
	url          = {https://arxiv.org/abs/1910.12603},
	copyright    = {Creative Commons Attribution Non Commercial Share Alike 4.0 International},
	keywords     = {Computers and Society (cs.CY), Cryptography and Security (cs.CR), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences}
}
@article{10.48550/arxiv.2011.07516,
	title        = {2CP: Decentralized Protocols to Transparently Evaluate Contributivity in Blockchain Federated Learning Environments},
	author       = {Cai, Harry and Rueckert, Daniel and Passerat-Palmbach, Jonathan},
	year         = 2020,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.2011.07516},
	url          = {https://arxiv.org/abs/2011.07516},
	copyright    = {Creative Commons Attribution Share Alike 4.0 International},
	keywords     = {Machine Learning (cs.LG), Distributed, Parallel, and Cluster Computing (cs.DC), FOS: Computer and information sciences, FOS: Computer and information sciences}
}
@inproceedings{8851649,
	title        = {Incentive Design for Efficient Federated Learning in Mobile Networks: A Contract Theory Approach},
	author       = {Kang, Jiawen and Xiong, Zehui and Niyato, Dusit and Yu, Han and Liang, Ying-Chang and Kim, Dong In},
	year         = 2019,
	booktitle    = {2019 IEEE VTS Asia Pacific Wireless Communications Symposium (APWCS)},
	volume       = {},
	number       = {},
	pages        = {1--5},
	doi          = {10.1109/VTS-APWCS.2019.8851649}
}
@article{li_blockchain_2021,
	title        = {Blockchain for federated learning toward secure distributed machine learning systems: a systemic survey},
	shorttitle   = {Blockchain for federated learning toward secure distributed machine learning systems},
	author       = {Li, Dun and Han, Dezhi and Weng, Tien-Hsiung and Zheng, Zibin and Li, Hongzhi and Liu, Han and Castiglione, Arcangelo and Li, Kuan-Ching},
	year         = 2021,
	month        = nov,
	journal      = {Soft Computing},
	doi          = {10.1007/s00500-021-06496-5},
	issn         = {1432-7643, 1433-7479},
	url          = {https://link.springer.com/10.1007/s00500-021-06496-5},
	urldate      = {2022-02-09},
	abstract     = {Federated learning (FL) is a promising decentralized deep learning technology, which allows users to update models cooperatively without sharing their data. FL is reshaping existing industry paradigms for mathematical modeling and analysis, enabling an increasing number of industries to build privacy-preserving, secure distributed machine learning models. However, the inherent characteristics of FL have led to problems such as privacy protection, communication cost, systems heterogeneity, and unreliability model upload in actual operation. Interestingly, the integration with Blockchain technology provides an opportunity to further improve the FL security and performance, besides increasing its scope of applications. Therefore, we denote this integration of Blockchain and FL as the Blockchain-based federated learning (BCFL) framework. This paper introduces an in-depth survey of BCFL and discusses the insights of such a new paradigm. In particular, we ﬁrst brieﬂy introduce the FL technology and discuss the challenges faced by such technology. Then, we summarize the Blockchain ecosystem. Next, we highlight the structural design and platform of BCFL. Furthermore, we present the attempts ins improving FL performance with Blockchain and several combined applications of incentive mechanisms in FL. Finally, we summarize the industrial application scenarios of BCFL.},
	language     = {en},
	file         = {Li et al. - 2021 - Blockchain for federated learning toward secure di.pdf:/Users/hacdias/Library/Mobile Documents/com~apple~CloudDocs/Papers/Thesis/Li et al. - 2021 - Blockchain for federated learning toward secure di.pdf:application/pdf}
}
@misc{10.48550/arxiv.2007.15145,
	title        = {Proof of Learning (PoLe): Empowering Machine Learning with Consensus Building on Blockchains},
	author       = {Lan, Yixiao and Liu, Yuan and Li, Boyang},
	year         = 2020,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.2007.15145},
	url          = {https://arxiv.org/abs/2007.15145},
	copyright    = {arXiv.org perpetual, non-exclusive license},
	keywords     = {Cryptography and Security (cs.CR), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences}
}
@article{10.48550/arxiv.1602.05629,
	title        = {Communication-Efficient Learning of Deep Networks from Decentralized Data},
	author       = {McMahan, H. Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and Arcas, Blaise Agüera y},
	year         = 2016,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.1602.05629},
	url          = {https://arxiv.org/abs/1602.05629},
	copyright    = {arXiv.org perpetual, non-exclusive license},
	keywords     = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences}
}
@misc{nakamoto2009bitcoin,
	title        = {Bitcoin: A peer-to-peer electronic cash system},
	author       = {Nakamoto, Satoshi},
	year         = 2009,
	url          = {http://www.bitcoin.org/bitcoin.pdf},
	added-at     = {2014-04-17T08:33:06.000+0200},
	biburl       = {https://www.bibsonomy.org/bibtex/23db66df0fc9fa2b5033f096a901f1c36/ngnn},
	interhash    = {423c2cdff70ba0cd0bca55ebb164d770},
	intrahash    = {3db66df0fc9fa2b5033f096a901f1c36},
	keywords     = {imported},
	timestamp    = {2014-04-17T08:33:06.000+0200}
}
@book{geron_2019,
	title        = {Hands-on machine learning with scikit-learn, Keras, and tensorflow: Concepts, tools and techniques to build Intelligent Systems},
	author       = {GERON, Aurelien},
	year         = 2019,
	publisher    = {O'Reilly},
	place        = {Beijing ; Boston ; Farnham etc.}
}
@article{9084352,
	title        = {Federated Learning: Challenges, Methods, and Future Directions},
	author       = {Li, Tian and Sahu, Anit Kumar and Talwalkar, Ameet and Smith, Virginia},
	year         = 2020,
	journal      = {IEEE Signal Processing Magazine},
	volume       = 37,
	number       = 3,
	pages        = {50--60},
	doi          = {10.1109/MSP.2020.2975749}
}
@article{10.1145/3298981,
	title        = {Federated Machine Learning: Concept and Applications},
	author       = {Yang, Qiang and Liu, Yang and Chen, Tianjian and Tong, Yongxin},
	year         = 2019,
	month        = {jan},
	journal      = {ACM Trans. Intell. Syst. Technol.},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	volume       = 10,
	number       = 2,
	doi          = {10.1145/3298981},
	issn         = {2157-6904},
	url          = {https://doi.org/10.1145/3298981},
	issue_date   = {March 2019},
	abstract     = {Today’s artificial intelligence still faces two major challenges. One is that, in most industries, data exists in the form of isolated islands. The other is the strengthening of data privacy and security. We propose a possible solution to these challenges: secure federated learning. Beyond the federated-learning framework first proposed by Google in 2016, we introduce a comprehensive secure federated-learning framework, which includes horizontal federated learning, vertical federated learning, and federated transfer learning. We provide definitions, architectures, and applications for the federated-learning framework, and provide a comprehensive survey of existing works on this subject. In addition, we propose building data networks among organizations based on federated mechanisms as an effective solution to allowing knowledge to be shared without compromising user privacy.},
	articleno    = 12,
	numpages     = 19,
	keywords     = {Federated learning, GDPR, transfer learning}
}
@article{10.1145/3412357,
	title        = {Federated Learning in a Medical Context: A Systematic Literature Review},
	author       = {Pfitzner, Bjarne and Steckhan, Nico and Arnrich, Bert},
	year         = 2021,
	month        = {jun},
	journal      = {ACM Trans. Internet Technol.},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	volume       = 21,
	number       = 2,
	doi          = {10.1145/3412357},
	issn         = {1533-5399},
	url          = {https://doi.org/10.1145/3412357},
	issue_date   = {June 2021},
	abstract     = {Data privacy is a very important issue. Especially in fields like medicine, it is paramount to abide by the existing privacy regulations to preserve patients’ anonymity. However, data is required for research and training machine learning models that could help gain insight into complex correlations or personalised treatments that may otherwise stay undiscovered. Those models generally scale with the amount of data available, but the current situation often prohibits building large databases across sites. So it would be beneficial to be able to combine similar or related data from different sites all over the world while still preserving data privacy. Federated learning has been proposed as a solution for this, because it relies on the sharing of machine learning models, instead of the raw data itself. That means private data never leaves the site or device it was collected on. Federated learning is an emerging research area, and many domains have been identified for the application of those methods. This systematic literature review provides an extensive look at the concept of and research into federated learning and its applicability for confidential healthcare datasets.},
	articleno    = 50,
	numpages     = 31,
	keywords     = {Federated learning}
}
@misc{ccaf,
	title        = {Cambridge Bitcoin Electricity Consumption Index},
	journal      = {Cambridge Centre for Alternative Finance},
	publisher    = {University of Cambridge},
	url          = {https://ccaf.io/cbeci/index/comparisons}
}
@misc{edwood_2020,
	title        = {Proof-of-work vs. proof-of-stake for scaling blockchains},
	author       = {Edwood, Frank},
	year         = 2020,
	month        = {Jun},
	journal      = {Cointelegraph},
	publisher    = {Cointelegraph},
	url          = {https://cointelegraph.com/news/proof-of-work-vs-proof-of-stake-for-scaling-blockchains}
}
@misc{binance_academy_2020,
	title        = {Proof of authority explained},
	author       = {Binance Academy},
	year         = 2020,
	month        = {Dec},
	journal      = {Binance Academy},
	publisher    = {Binance Academy},
	url          = {https://academy.binance.com/en/articles/proof-of-authority-explained}
}
@article{qu_blockchain-enabled_2022,
	title        = {Blockchain-{Enabled} {Federated} {Learning}: {A} {Survey}},
	shorttitle   = {Blockchain-{Enabled} {Federated} {Learning}},
	author       = {Qu, Youyang and Uddin, Md Palash and Gan, Chenquan and Xiang, Yong and Gao, Longxiang and Yearwood, John},
	year         = 2022,
	month        = mar,
	journal      = {ACM Computing Surveys},
	pages        = 3524104,
	doi          = {10.1145/3524104},
	issn         = {0360-0300, 1557-7341},
	url          = {https://dl.acm.org/doi/10.1145/3524104},
	urldate      = {2022-04-13},
	abstract     = {Federated learning (FL) is experiencing fast booming in recent years, which is jointly promoted by the prosperity of machine learning and Artificial Intelligence along with the emerging privacy issues. In the FL paradigm, a central server and local end devices maintain the same model by exchanging model updates instead of raw data, with which the privacy of data stored on end devices is not directly revealed. In this way, the privacy violation caused by the growing collection of sensitive data can be mitigated. However, the performance of FL with a central server is reaching a bottleneck while new threats are emerging simultaneously. There are various reasons, among which the most significant ones are centralized processing, data falsification, and lack of incentives. To accelerate the proliferation of FL, blockchain-enabled FL has attracted substantial attention from both academia and industry. A considerable number of novel solutions are devised to meet the emerging demands of diverse scenarios. Blockchain-enabled FL provides both theories and techniques to improve the performances of FL from various perspectives. In this survey, we will comprehensively summarize and evaluate existing variants of blockchain-enabled FL, identify the emerging challenges, and propose potentially promising research directions in this under-explored domain.},
	language     = {en},
	file         = {Qu et al. - 2022 - Blockchain-Enabled Federated Learning A Survey.pdf:/Users/hacdias/Library/Mobile Documents/com~apple~CloudDocs/Papers/Thesis/Qu et al. - 2022 - Blockchain-Enabled Federated Learning A Survey.pdf:application/pdf}
}
@misc{Castro99practicalbyzantine,
	title        = {Practical Byzantine Fault Tolerance},
	author       = {Miguel Castro and Barbara Loskov},
	year         = 1999
}
@article{9403374,
	title        = {Federated Learning Meets Blockchain in Edge Computing: Opportunities and Challenges},
	author       = {Nguyen, Dinh C. and Ding, Ming and Pham, Quoc-Viet and Pathirana, Pubudu N. and Le, Long Bao and Seneviratne, Aruna and Li, Jun and Niyato, Dusit and Poor, H. Vincent},
	year         = 2021,
	journal      = {IEEE Internet of Things Journal},
	volume       = 8,
	number       = 16,
	pages        = {12806--12825},
	doi          = {10.1109/JIOT.2021.3072611}
}

@misc{10.48550/arxiv.2110.02182,
  doi = {10.48550/ARXIV.2110.02182},
  
  url = {https://arxiv.org/abs/2110.02182},
  
  author = {Wang, Zhilin and Hu, Qin},
  
  keywords = {Cryptography and Security (cs.CR), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Blockchain-based Federated Learning: A Comprehensive Survey},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{10.48550/arxiv.2104.10501,
  doi = {10.48550/ARXIV.2104.10501},
  
  url = {https://arxiv.org/abs/2104.10501},
  
  author = {Zhou, Jiehan and Zhang, Shouhua and Lu, Qinghua and Dai, Wenbin and Chen, Min and Liu, Xin and Pirttikangas, Susanna and Shi, Yang and Zhang, Weishan and Herrera-Viedma, Enrique},
  
  keywords = {Distributed, Parallel, and Cluster Computing (cs.DC), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {A Survey on Federated Learning and its Applications for Accelerating Industrial Internet of Things},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@InProceedings{10.1007/978-981-15-9213-3_12,
author="Kang, Jiawen
and Xiong, Zehui
and Jiang, Chunxiao
and Liu, Yi
and Guo, Song
and Zhang, Yang
and Niyato, Dusit
and Leung, Cyril
and Miao, Chunyan",
editor="Zheng, Zibin
and Dai, Hong-Ning
and Fu, Xiaodong
and Chen, Benhui",
title="Scalable and Communication-Efficient Decentralized Federated Edge Learning with Multi-blockchain Framework",
booktitle="Blockchain and Trustworthy Systems",
year="2020",
publisher="Springer Singapore",
address="Singapore",
pages="152--165",
abstract="The emerging Federated Edge Learning (FEL) technique has drawn considerable attention, which not only ensures good machine learning performance but also solves ``data island'' problems caused by data privacy concerns. However, large-scale FEL still faces following crucial challenges: (i) there lacks a secure and communication-efficient model training scheme for FEL; (2) there is no scalable and flexible FEL framework for updating local models and global model sharing (trading) management. To bridge the gaps, we first propose a blockchain-empowered secure FEL system with a hierarchical blockchain framework consisting of a main chain and subchains. This framework can achieve scalable and flexible decentralized FEL by individually manage local model updates or model sharing records for performance isolation. A Proof-of-Verifying consensus scheme is then designed to remove low-quality model updates and manage qualified model updates in a decentralized and secure manner, thereby achieving secure FEL. To improve communication efficiency of the blockchain-empowered FEL, a gradient compression scheme is designed to generate sparse but important gradients to reduce communication overhead without compromising accuracy, and also further strengthen privacy preservation of training data. The security analysis and numerical results indicate that the proposed schemes can achieve secure, scalable, and communication-efficient decentralized FEL.",
isbn="978-981-15-9213-3"
}
